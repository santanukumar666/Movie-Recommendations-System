## Movie Recommendations using Content Based Filtering
In this kernel we'll be building a baseline Movie Recommendation System using TMDB 5000 Movie Dataset. For novices like me this kernel will pretty much serve as a foundation in recommendation systems and will provide you with something to start with.

In this kernel we would be using content based filtering to recommend movies.

In this recommender system the content of the movie (overview, cast, crew, keyword, tagline etc) is used to find its similarity with other movies. Then the movies that are most likely to be similar are recommended.

The first dataset contains the following features:- 
```
movie_id - A unique identifier for each movie.

cast - The name of lead and supporting actors.

crew - The name of Director, Editor, Composer, Writer etc.
```
The second dataset has the following features:- budget - The budget in which the movie was made.
```
genre - The genre of the movie, Action, Comedy ,Thriller etc.

homepage - A link to the homepage of the movie.

id - This is infact the movie_id as in the first dataset.

keywords - The keywords or tags related to the movie.

original_language - The language in which the movie was made.

original_title - The title of the movie before translation or adaptation.

overview - A brief description of the movie.

popularity - A numeric quantity specifying the movie popularity.

production_companies - The production house of the movie.

production_countries - The country in which it was produced.

release_date - The date on which it was released.

revenue - The worldwide revenue generated by the movie.

runtime - The running time of the movie in minutes.

status - "Released" or "Rumored".

tagline - Movie's tagline.

title - Title of the movie.

vote_average - average ratings the movie recieved.

vote_count - the count of votes recieved.
```

- Term Frequency is the relative frequency of a word in a document and is given as (term instances/total instances).
Inverse Document Frequency is the relative count of documents containing the term is given as log(number of documents/documents with term).
The overall importance of each word to the documents in which they appear is equal to TF * IDF
This will give us a matrix where each column represents a word in the overview vocabulary (all the words that appear in at least one document) and each row represents a movie, as before.
This is done to reduce the importance of words that occur frequently in plot overviews and therefore, their significance in computing the final similarity score.
Scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines.


- We see that over 20,000 different words were used to describe the 4800 movies in our dataset.
With this matrix, we can now compute a similarity score. There are several candidates for this; such as the euclidean, the pearson and the cosine similarity scores. There is no right answer to which score is the best. Different scores work well in different scenarios and it is often a good idea to experiment with different metrics.
We will be using the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies. We use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate.
Mathematically, it is defined as follows:

![cosine_similarity](https://user-images.githubusercontent.com/60546202/157675938-7acae7b1-39da-40e0-98d2-6bddecd1e7ab.png)

